{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import string\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "from datetime import date, datetime\n",
    "from requests.exceptions import TooManyRedirects, ConnectionError, ReadTimeout\n",
    "from http.client import RemoteDisconnected\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para realizar el web scrapping y almacenar la información en archivos de texto (descargar resultados de carreras):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status():\n",
    "  \"\"\"Función que analiza si existe el directorio backups, y de ser así importa los CSV correspondientes para el\n",
    "  funcionamiento del programa. Si el directorio no existe, se asume que es la primera ejecución del programa y se declaran\n",
    "  todas las variables necesarias sin datos. También se evalúa si durante la ejecución anterior se interrumpió el proceso\n",
    "  de descarga de carreras  inesperadamente (fallas de conexión, corte de energía, etc),  y en caso afirmativo activa\n",
    "  la corrección de errores.\n",
    "  \"\"\"\n",
    "\n",
    "  try:\n",
    "    if os.listdir('./backups'):\n",
    "      directorios = True\n",
    "\n",
    "      lista_existentes = []\n",
    "\n",
    "      for c in os.listdir('./backups/carreras'): # Se crea una lista con todos los IDs descargados históricamente.\n",
    "        c = c.replace('.txt','')\n",
    "        lista_existentes.append(int(c))\n",
    "\n",
    "      max_existente = max(lista_existentes) # Se almacenan estos datos como parte de la información a brindar al usuario durante la ejecución.\n",
    "      min_existente = min(lista_existentes)\n",
    "\n",
    "      with open('./backups/en_proceso.csv', mode='r', newline='') as archivo_csv:\n",
    "        lector = csv.reader(archivo_csv)\n",
    "        en_proceso = next(lector)\n",
    "        en_proceso = bool(en_proceso[0])  # Según sea el contenido del archivo en_proceso.csv, se asigna valor booleano a la variable.\n",
    "\n",
    "      with open('./backups/fallidos.csv', mode='r', newline='') as archivo_csv:\n",
    "        lector = csv.reader(archivo_csv)\n",
    "        lista_fallidos = next(lector) # Esta lista contiene todos los IDs de carreras que no fueron encontrados hasta la fecha.\n",
    "\n",
    "      with open('./backups/ultima_act_fecha.csv', mode='r', newline='') as archivo_csv:\n",
    "        lector = csv.reader(archivo_csv)\n",
    "        fecha_list = next(lector) # Dato informativo para el usuario, sobre última fecha de actualización de la base de resultados.\n",
    "\n",
    "      fecha_str = ''.join(fecha_list)\n",
    "      fecha_obj = datetime.strptime(fecha_str, '%d-%m-%Y')\n",
    "      fecha = fecha_obj.strftime('%d-%m-%Y') # Se formatea la fecha a formato datetime.\n",
    "\n",
    "      with open('./backups/ultima_act_tiempo.csv', mode='r', newline='') as archivo_csv:\n",
    "        lector = csv.reader(archivo_csv)\n",
    "        tiempo = next(lector)  # Indica cuánto tiempo demoró la última actualización.\n",
    "\n",
    "  # Si no encuentra el directorio especificado en el try, se asume que es la primera ejecución\n",
    "  # y todas las variables se declaran sin asignarles valor útil. Se crea también el directorio 'calendario'.\n",
    "\n",
    "  except OSError:\n",
    "      directorios = False\n",
    "      lista_fallidos = 'Sin datos'\n",
    "      fecha = 'Sin datos'\n",
    "      tiempo = 'Sin datos'\n",
    "      min_existente = 'Sin datos'\n",
    "      max_existente = 'Sin datos'\n",
    "      lista_existentes = 'Sin datos'\n",
    "      en_proceso = None\n",
    "      os.mkdir('./calendario')\n",
    "\n",
    "  return directorios, lista_fallidos, fecha, tiempo, min_existente, max_existente, lista_existentes, en_proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprobar_errores(lista_existentes, min_existente, max_existente):\n",
    "    \"\"\"Esta función es activada por la función integradora d_c, definida más adelante. Si la variable 'en_proceso' tiene\n",
    "    valor True, significa que durante la última ejecución el proceso se interrumpió inesperadamente, durante la descarga\n",
    "    de nuevas carreras o reintentos de fallidas, sin llegar a actualizar el CSV correspondiente, por lo tanto pudiéndose\n",
    "    haber generado inconsistencias en la información. De ser el caso, la función procede a realizar una revisión de las\n",
    "    listas pertinentes y rectificar los registros antes de continuar. Por último, en caso de que la interrupción se haya\n",
    "    generado durante la primera ejecución del programa, verifica si existe el archivo procesados.csv y df_resultados.csv,\n",
    "    y los crea en caso de que no existan.\n",
    "\n",
    "    Argumentos:\n",
    "\n",
    "    lista_existentes -- Lista de todos los ID descargados, generada por la función status().\n",
    "    min_existente -- Mínimo ID descargado, obtenido por la función status().\n",
    "    max_existente -- Máximo ID descargado , obtenido por la función status().\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def corregir_lista_fallidos(lista_existentes, min_existente, max_existente):\n",
    "\n",
    "        lista_fallidas_correccion = []\n",
    "\n",
    "        for i in range(min_existente, max_existente):  # Se recorren los IDs existentes entre el mínimo y máximo, y se evalúa si existen en la lista de existentes.\n",
    "          if i not in lista_existentes:\n",
    "            lista_fallidas_correccion.append(i) # Si no se encuentran la lista de existentes, se asume que es fue un intento fallido, por lo cual se agrega a esta última lista.\n",
    "\n",
    "        with open('./backups/fallidos.csv', mode='w', newline='') as archivo_csv:\n",
    "          escritor = csv.writer(archivo_csv)\n",
    "          escritor.writerow(lista_fallidas_correccion)  # Se actualiza el archivo de respaldo.\n",
    "\n",
    "        print('Lista de fallidos verificada.')\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        return lista_fallidas_correccion\n",
    "\n",
    "    def verificar_procesados_y_resultados():\n",
    "        if not os.path.exists('./backups/procesados.csv'): # Comportamiento en caso de no encontrarse el archivo procesados.csv\n",
    "\n",
    "            procesados = []\n",
    "            with open('./backups/procesados.csv', mode='w', newline='') as archivo_csv:\n",
    "                escritor = csv.writer(archivo_csv)\n",
    "                escritor.writerow(procesados)\n",
    "            print('Lista de carreras procesadas generada (primera ejecución)')\n",
    "            time.sleep(0.2)\n",
    "        else:\n",
    "          print('No se encontraron problemas con la lista de carreras procesadas.')\n",
    "          time.sleep(0.2)\n",
    "\n",
    "        if not os.path.exists('./backups/df_resultados.csv'): # Comportamiento en caso de no encontrarse el df_resultados.csv\n",
    "            df_resultados = pd.DataFrame({\n",
    "                'id':[],\n",
    "                'nombre':[],\n",
    "                'fecha':[],\n",
    "                'hora':[],\n",
    "                'metros':[],\n",
    "                'suelo':[],\n",
    "                'condicion':[],\n",
    "                'posicion':[],\n",
    "                'numero':[],\n",
    "                'competidor':[],\n",
    "                'diferencia':[],\n",
    "                'peso_jockey':[],\n",
    "                'peso_caballo':[],\n",
    "                'pagaria':[]\n",
    "                })\n",
    "            df_resultados.to_csv('./backups/df_resultados.csv')\n",
    "            print('Base de datos de resultados generada (primera ejecución)')\n",
    "            time.sleep(0.2)\n",
    "        else:\n",
    "          print('No se encontraron problemas con la base de datos de resultados.')\n",
    "          time.sleep(0.2)\n",
    "\n",
    "    lista_fallidos_corregida = corregir_lista_fallidos(lista_existentes, min_existente, max_existente)\n",
    "    verificar_procesados_y_resultados()\n",
    "\n",
    "    return lista_fallidos_corregida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descargar_carreras(directorios, lista_fallidos, fecha, tiempo, min_existente, max_existente, lista_existentes):\n",
    "    \"\"\"Según sea la primera ejecución o no (if directorios == True/False), genera los directorios necesarios y comienza\n",
    "    la primera descarga de resultados de carreras\n",
    "\n",
    "    Argumentos: Son generados por la función status() y/o eventualmente por la función comprobar_errores().\n",
    "    \"\"\"\n",
    "\n",
    "    if directorios == True:\n",
    "            print('- Actualización de archivos -')\n",
    "\n",
    "            print(f\"Actualmente existen {len(lista_fallidos)} ID's de carreras no encontrados\")\n",
    "            time.sleep(0.1)\n",
    "            reintentar = input('¿Desea reintentar descargar algunos de ellos? (s/n)')\n",
    "\n",
    "            if reintentar.lower() == 's':\n",
    "                cantidad = int(input(\"Indique cantidad de ID's a reintentar (LIFO) o 0 para incluir todos:\"))*(-1)\n",
    "                # El (-1) obedece al orden LIFO (Last In First Out) en el que se reintentan los IDs no encontrados,\n",
    "                # contenidos en lista_fallidos, es decir que se considera la cantidad a reintentar contando desde el\n",
    "                # más reciente hasta el más antiguo, como está definido en la variable lista_fallidos_recortada\n",
    "                # a continuación:\n",
    "\n",
    "                lista_fallidos_recortada = lista_fallidos[cantidad:]\n",
    "            else:\n",
    "                print('* Paso omitido *')\n",
    "\n",
    "            # A continuación se presentan algunos datos sobre la última ejecución y la información\n",
    "            # presente en las bases de datos, para que el usuario pueda utilizarla para decidir\n",
    "            # qué rango de ID's intentar descargar. Nótese que el usuario debe investigar previamente\n",
    "            # el sitio web al cual se realizará el web scrapping, para tener una idea del máximo ID\n",
    "            # que está disponible online.\n",
    "\n",
    "            print(f'- La última actualización tuvo lugar el día {fecha}, y el tiempo de procesamiento fue de {tiempo[0]} horas -')\n",
    "            time.sleep(0.1)\n",
    "            explorar = input(\"¿Desea buscar por rango de ID's? (s/n)\")\n",
    "\n",
    "            if explorar.lower() == 's':\n",
    "                print(\"Ingrese rango de ID's a buscar:\")\n",
    "                print(f'* ID mínimo descargado: {min_existente} *')\n",
    "                print(f'* ID máximo descargado: {max_existente} *')\n",
    "                time.sleep(0.2)\n",
    "                inicio = int(input('Inicial:'))\n",
    "                print(f\"ID inicial: {inicio}\")\n",
    "                fin = int(input('Final:'))+1\n",
    "                print(f\"ID final: {fin-1}\")\n",
    "\n",
    "            print('Comenzando actualización...')\n",
    "\n",
    "            tiempo_inicial_actu = time.perf_counter()\n",
    "\n",
    "            if reintentar.lower() == 's': # Aquí comienza el reintento de fallidos, si el usuario así lo indicó.\n",
    "\n",
    "                with open('./backups/en_proceso.csv', mode='w', newline='') as archivo_csv:\n",
    "                    escritor = csv.writer(archivo_csv)\n",
    "                    escritor.writerow([True]) # Se marca flag de proceso iniciado, con el que, en la próxima ejecución, se comprobará si existieron interrupciones durante el proceso.\n",
    "\n",
    "                print(\"Reintentando ID's fallidos...\")\n",
    "                encontrados = 0\n",
    "\n",
    "                for i in lista_fallidos_recortada:\n",
    "\n",
    "                    url = f\"https://www.palermo.com.ar/es/turf/ver-carrera/{i}\"\n",
    "                    print(url)\n",
    "\n",
    "                    success = False\n",
    "                    while not success:\n",
    "\n",
    "                        try:\n",
    "                            response = requests.get(url)\n",
    "                            response.encoding = 'utf-8'\n",
    "                            # Verifica si la solicitud fue exitosa (código 200):\n",
    "                            if response.status_code == 200:\n",
    "                                encontrados += 1\n",
    "                                # Si existe el ID, elimina el ID de la lista de fallidos:\n",
    "                                lista_fallidos.remove(i)\n",
    "                                # Se parsea el contenido HTML de la carrera\n",
    "                                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                                # Se obtiene todo el texto visible\n",
    "                                texto_visible = soup.get_text(separator=' ', strip=True)\n",
    "                                # Limpieza del texto: Se eliminan espacios múltiples, saltos de línea innecesarios, etc.\n",
    "                                texto_limpio = re.sub(r'\\s+', ' ', texto_visible)\n",
    "                                # Se guarda el texto limpio en un archivo .txt\n",
    "                                with open(f'./backups/carreras/{i}.txt', 'w', encoding='utf-8') as file:\n",
    "                                    file.write(texto_limpio)\n",
    "                                success = True # Condición para finalizar el bucle while y pasar a la siguiente iteración del bucle for.\n",
    "\n",
    "                        except TooManyRedirects as e:\n",
    "                            success = True # Si se detecta la excepción indicada, se asume que el ID no existe en la web,\n",
    "                                           # por lo cual se considera que el intento fue exitoso a nivel operativo, y el ID permanece en la lista de fallidos.\n",
    "                            continue # Se pasa a la siguiente iteración del bucle while finalizándolo, ya que estará la variable success en True,\n",
    "                                     # pasando así a la siguiente iteración del bucle for.\n",
    "\n",
    "                        except (RemoteDisconnected, ConnectionError, ReadTimeout) as e:\n",
    "\n",
    "                            # Lógica para manejar errores de conexión. Se le da la opción al usuario para reintentar, o abortar el proceso.\n",
    "                            # Si el usuario decide abortar el proceso, se actualizan las variables de control y se guarda\n",
    "                            # en los archivos CSV de respaldo, permitiendo así no perder la información obtenida hasta el momento\n",
    "                            # y evitando inconsistencias.\n",
    "\n",
    "                            print(f\"Error de desconexión: {e}\")\n",
    "                            print(\"Por favor, verificar la conexión a internet, e ingresar 's' para reintentar o 'n' para guardar el progreso y salir del programa.\")\n",
    "                            opcion = input('Ingrese opción (s/n):')\n",
    "\n",
    "                            if opcion.lower() == 's':\n",
    "                                continue\n",
    "                            else:\n",
    "                                if encontrados > 0:\n",
    "                                    print(f\"Se recuperaron {encontrados} carreras de la lista de ID's fallidos.\")\n",
    "                                    # Se exporta el nuevo csv actualizado\n",
    "                                    with open('./backups/fallidos.csv', mode='w', newline='') as archivo_csv:\n",
    "                                        escritor = csv.writer(archivo_csv)\n",
    "                                        escritor.writerow(lista_fallidos)\n",
    "\n",
    "                                    with open('./backups/en_proceso.csv', mode='w', newline='') as archivo_csv:\n",
    "                                        escritor = csv.writer(archivo_csv)\n",
    "                                        escritor.writerow([None]) # Se marca flag de proceso terminado\n",
    "\n",
    "                                    tiempo_final_actu = time.perf_counter()\n",
    "                                    tiempo_actu = [round((tiempo_final_actu-tiempo_inicial_actu)/3600, 2)]\n",
    "                                    fecha_actu = [date.today().strftime('%d-%m-%Y')]\n",
    "\n",
    "                                    with open('./backups/ultima_act_fecha.csv', mode='w', newline='') as archivo_csv:\n",
    "                                        escritor = csv.writer(archivo_csv)\n",
    "                                        escritor.writerow(fecha_actu)\n",
    "\n",
    "                                    with open('./backups/ultima_act_tiempo.csv', mode='w', newline='') as archivo_csv:\n",
    "                                        escritor = csv.writer(archivo_csv)\n",
    "                                        escritor.writerow(tiempo_actu)\n",
    "                                else:\n",
    "                                    print(\"No se recuperó ninguna carrera de la lista de ID's fallidos.\")\n",
    "                                return\n",
    "\n",
    "                        time.sleep(1)\n",
    "\n",
    "                if encontrados > 0:\n",
    "                    print(f\"Se recuperaron {encontrados} carreras de la lista de ID's fallidos.\")\n",
    "                    # Se exporta el nuevo csv actualizado\n",
    "                    with open('./backups/fallidos.csv', mode='w', newline='') as archivo_csv:\n",
    "                        escritor = csv.writer(archivo_csv)\n",
    "                        escritor.writerow(lista_fallidos)\n",
    "                else:\n",
    "                    print(\"No se recuperó ninguna carrera de la lista de ID's fallidos.\")\n",
    "\n",
    "                with open('./backups/en_proceso.csv', mode='w', newline='') as archivo_csv:\n",
    "                    escritor = csv.writer(archivo_csv)\n",
    "                    escritor.writerow([None]) # Se marca flag de proceso terminado\n",
    "            else:\n",
    "                encontrados = 0\n",
    "\n",
    "            # El bloque siguiente funciona de manera muy similar al anterior, con la diferencia de que es el usuario quien\n",
    "            # indica los ID inicial y final a recorrer.\n",
    "\n",
    "            if explorar.lower() == 's':\n",
    "                print(f\"Explorando nuevos ID's...\")\n",
    "                indi = 0\n",
    "                exitosos = 0\n",
    "                fallidos = 0\n",
    "                recuperados = 0\n",
    "\n",
    "                with open('./backups/en_proceso.csv', mode='w', newline='') as archivo_csv:\n",
    "                        escritor = csv.writer(archivo_csv)\n",
    "                        escritor.writerow([True])\n",
    "\n",
    "                for i in range(inicio, fin):\n",
    "\n",
    "                    if i in lista_existentes:\n",
    "                        url = f\"https://www.palermo.com.ar/es/turf/ver-carrera/{i}\"\n",
    "                        print(url)\n",
    "                        print(f'ID {i} ya existente. Omitiendo..')\n",
    "                    else:\n",
    "                        url = f\"https://www.palermo.com.ar/es/turf/ver-carrera/{i}\"\n",
    "                        print(url)\n",
    "\n",
    "                        success = False\n",
    "                        while not success:\n",
    "\n",
    "                            try:\n",
    "                                response = requests.get(url)\n",
    "                                response.encoding = 'utf-8'\n",
    "\n",
    "                                if response.status_code == 200:\n",
    "                                    indi = i\n",
    "                                    if str(i) in lista_fallidos:\n",
    "                                        recuperados += 1\n",
    "                                        lista_fallidos.remove(str(i))\n",
    "                                    else:\n",
    "                                        exitosos += 1\n",
    "\n",
    "                                    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                                    texto_visible = soup.get_text(separator=' ', strip=True)\n",
    "                                    texto_limpio = re.sub(r'\\s+', ' ', texto_visible)\n",
    "\n",
    "                                    with open(f'./backups/carreras/{i}.txt', 'w', encoding='utf-8') as file:\n",
    "                                        file.write(texto_limpio)\n",
    "                                    success = True\n",
    "\n",
    "                            except TooManyRedirects as e:\n",
    "                                fallidos += 1\n",
    "                                if str(i) not in lista_fallidos:\n",
    "                                    lista_fallidos.append(i)\n",
    "                                success = True\n",
    "\n",
    "                            except (RemoteDisconnected, ConnectionError, ReadTimeout) as e:\n",
    "\n",
    "                                print(f\"Error de desconexión: {e}\")\n",
    "                                print(\"Por favor, verificar la conexión a internet, e ingresar 's' para reintentar o 'n' para guardar el progreso y salir del programa.\")\n",
    "                                opcion = input('Ingrese opción (s/n):')\n",
    "\n",
    "                                if opcion.lower() == 's':\n",
    "                                    continue\n",
    "                                else:\n",
    "\n",
    "                                    if exitosos > 0 or recuperados > 0:\n",
    "\n",
    "                                        fecha_actu = [date.today().strftime('%d-%m-%Y')]\n",
    "                                        tiempo_final_actu = time.perf_counter()\n",
    "                                        tiempo_actu = [round((tiempo_final_actu-tiempo_inicial_actu)/3600, 2)]\n",
    "\n",
    "                                        with open('./backups/ultima_act_fecha.csv', mode='w', newline='') as archivo_csv:\n",
    "                                            escritor = csv.writer(archivo_csv)\n",
    "                                            escritor.writerow(fecha_actu)\n",
    "\n",
    "                                        with open('./backups/ultima_act_tiempo.csv', mode='w', newline='') as archivo_csv:\n",
    "                                            escritor = csv.writer(archivo_csv)\n",
    "                                            escritor.writerow(tiempo_actu)\n",
    "\n",
    "                                    if fallidos > 0:\n",
    "\n",
    "                                        lista_existentes_act = []\n",
    "                                        lista_fallidos_purgada = []\n",
    "\n",
    "                                        for c in os.listdir('./backups/carreras'):\n",
    "                                            c = c.replace('.txt','')\n",
    "                                            lista_existentes_act.append(int(c))\n",
    "\n",
    "                                        for n in lista_fallidos:\n",
    "                                            if int(n) < max(lista_existentes_act):\n",
    "                                                lista_fallidos_purgada.append(n)\n",
    "\n",
    "                                        with open('./backups/fallidos.csv', mode='w', newline='') as archivo_csv:\n",
    "                                                escritor = csv.writer(archivo_csv)\n",
    "                                                escritor.writerow(lista_fallidos_purgada)\n",
    "\n",
    "                                    with open('./backups/en_proceso.csv', mode='w', newline='') as archivo_csv:\n",
    "                                            escritor = csv.writer(archivo_csv)\n",
    "                                            escritor.writerow([None])   # Se marca flag de proceso terminado\n",
    "\n",
    "                                    print('* Actualización interrumpida *')\n",
    "                                    print('Nuevas carreras descargadas:', exitosos)\n",
    "                                    print('Carreras recuperadas (ex-fallidas):', encontrados + recuperados)\n",
    "                                    print('Páginas no encontradas:', fallidos)\n",
    "                                    print('ID máximo encontrado:', indi)\n",
    "                                    print(f'Tiempo de procesamiento: {tiempo_actu[0]} horas')\n",
    "                                    return\n",
    "                            time.sleep(1)\n",
    "\n",
    "                with open('./backups/en_proceso.csv', mode='w', newline='') as archivo_csv:\n",
    "                    escritor = csv.writer(archivo_csv)\n",
    "                    escritor.writerow([None])   # Se marca flag de proceso terminado\n",
    "            else:\n",
    "                exitosos = 0\n",
    "                fallidos = 0\n",
    "                recuperados = 0\n",
    "                indi = 'N/A'\n",
    "\n",
    "            tiempo_final_actu = time.perf_counter()\n",
    "            tiempo_actu = [round((tiempo_final_actu-tiempo_inicial_actu)/3600, 2)]\n",
    "\n",
    "            if exitosos > 0 or encontrados > 0 or recuperados > 0:\n",
    "                fecha_actu = [date.today().strftime('%d-%m-%Y')]\n",
    "\n",
    "                with open('./backups/ultima_act_fecha.csv', mode='w', newline='') as archivo_csv:\n",
    "                    escritor = csv.writer(archivo_csv)\n",
    "                    escritor.writerow(fecha_actu)\n",
    "\n",
    "                with open('./backups/ultima_act_tiempo.csv', mode='w', newline='') as archivo_csv:\n",
    "                    escritor = csv.writer(archivo_csv)\n",
    "                    escritor.writerow(tiempo_actu)\n",
    "\n",
    "            if fallidos > 0 or recuperados > 0:\n",
    "\n",
    "                lista_existentes_act = []\n",
    "                lista_fallidos_purgada = []\n",
    "\n",
    "                for c in os.listdir('./backups/carreras'):\n",
    "                    c = c.replace('.txt','')\n",
    "                    lista_existentes_act.append(int(c))\n",
    "\n",
    "                for n in lista_fallidos:\n",
    "                    if int(n) < max(lista_existentes_act):\n",
    "                        lista_fallidos_purgada.append(n)\n",
    "\n",
    "                with open('./backups/fallidos.csv', mode='w', newline='') as archivo_csv:\n",
    "                            escritor = csv.writer(archivo_csv)\n",
    "                            escritor.writerow(lista_fallidos_purgada)\n",
    "\n",
    "            print('* Actualización finalizada *')\n",
    "            print('Nuevas carreras descargadas:', exitosos)\n",
    "            print('Carreras recuperadas (ex-fallidas):', encontrados + recuperados)\n",
    "            print('Páginas no encontradas:', fallidos)\n",
    "            print('ID máximo encontrado:', indi)\n",
    "            print(f'Tiempo de procesamiento: {tiempo_actu[0]} horas')\n",
    "\n",
    "    else:\n",
    "        print('- Primera ejecución -')\n",
    "        print('* Creando estructura de directorios *')\n",
    "        lista_fallidos = []\n",
    "        indi = 0\n",
    "        exitosos = 0\n",
    "        fallidos = 0\n",
    "        tiempo_inicial = time.perf_counter()\n",
    "        os.makedirs('./backups/carreras', exist_ok=True)\n",
    "        time.sleep(1)\n",
    "        print('Finalizado\\n')\n",
    "\n",
    "        print(\"- Ingrese el rango de ID's de las carreras a buscar/descargar -\")\n",
    "        print(\"- Se estima que cada año contiene ~5600 ID's. La primera carrera de 2022 posee ID 193261 -\")\n",
    "        inicio = int(input('Inicial:'))\n",
    "        print(f\"ID inicial: {inicio}\")\n",
    "        fin = int(input('Final:'))+1\n",
    "        print(f\"ID final: {fin-1}\")\n",
    "        print('Comenzando descarga...')\n",
    "\n",
    "        with open('./backups/en_proceso.csv', mode='w', newline='') as archivo_csv:\n",
    "            escritor = csv.writer(archivo_csv)\n",
    "            escritor.writerow([True])   # Se marca flag de proceso iniciado\n",
    "\n",
    "        for i in range(inicio, fin):\n",
    "            url = f\"https://www.palermo.com.ar/es/turf/ver-carrera/{i}\"\n",
    "            print(url)\n",
    "\n",
    "            success = False\n",
    "            while not success:\n",
    "\n",
    "                try:\n",
    "                    response = requests.get(url)\n",
    "                    response.encoding = 'utf-8'\n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        indi = i\n",
    "                        exitosos += 1\n",
    "\n",
    "                        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                        texto_visible = soup.get_text(separator=' ', strip=True)\n",
    "                        texto_limpio = re.sub(r'\\s+', ' ', texto_visible)\n",
    "\n",
    "                        with open(f'./backups/carreras/{i}.txt', 'w', encoding='utf-8') as file:\n",
    "                            file.write(texto_limpio)\n",
    "                        success = True\n",
    "\n",
    "                except TooManyRedirects as e:\n",
    "                    fallidos += 1\n",
    "                    lista_fallidos.append(i)\n",
    "                    success = True\n",
    "\n",
    "                except (RemoteDisconnected, ConnectionError, ReadTimeout) as e:\n",
    "                    print(f\"Error de desconexión: {e}\")\n",
    "                    print(\"Por favor, verificar la conexión a internet, e ingresar 's' para reintentar o 'n' para guardar el progreso y salir del programa.\")\n",
    "                    opcion = input('Ingrese opción (s/n):')\n",
    "                    if opcion == 's':\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        if fallidos > 0 or exitosos > 0:\n",
    "                            tiempo_final = time.perf_counter()\n",
    "                            tiempo = [round((tiempo_final - tiempo_inicial)/3600, 2)]\n",
    "                            fecha = [date.today().strftime('%d-%m-%Y')]\n",
    "\n",
    "                            with open('./backups/ultima_act_fecha.csv', mode='w', newline='') as archivo_csv:\n",
    "                                escritor = csv.writer(archivo_csv)\n",
    "                                escritor.writerow(fecha)\n",
    "                            with open('./backups/ultima_act_tiempo.csv', mode='w', newline='') as archivo_csv:\n",
    "                                escritor = csv.writer(archivo_csv)\n",
    "                                escritor.writerow(tiempo)\n",
    "\n",
    "                            if fallidos > 0:\n",
    "                                lista_existentes_act = []\n",
    "                                lista_fallidos_purgada = []\n",
    "\n",
    "                                for c in os.listdir('./backups/carreras'):\n",
    "                                    c = c.replace('.txt','')\n",
    "                                    lista_existentes_act.append(int(c))\n",
    "\n",
    "                                # El siguiente bucle for se encarga de que en la lista de fallidos no se almacenen IDs que\n",
    "                                # superen el máximo ID encontrado, ya que es probable que dichos IDs sean utilizados\n",
    "                                # para identificar futuras carreras. De esta forma, se logra que la información de la lista\n",
    "                                # de fallidos sea más confiable.\n",
    "\n",
    "                                for n in lista_fallidos:\n",
    "                                    if int(n) < max(lista_existentes_act):\n",
    "                                        lista_fallidos_purgada.append(n)\n",
    "\n",
    "                                with open('./backups/fallidos.csv', mode='w', newline='') as archivo_csv:\n",
    "                                    escritor = csv.writer(archivo_csv)\n",
    "                                    escritor.writerow(lista_fallidos_purgada)\n",
    "\n",
    "                        with open('./backups/en_proceso.csv', mode='w', newline='') as archivo_csv:\n",
    "                            escritor = csv.writer(archivo_csv)\n",
    "                            escritor.writerow([None])   # Se marca flag de proceso finalizado\n",
    "\n",
    "                        print('* Descarga interrumpida *')\n",
    "                        print('Carreras descargadas:', exitosos)\n",
    "                        print('Páginas no encontradas:', fallidos)\n",
    "                        print('ID máximo encontrado:', indi)\n",
    "                        print(f'Tiempo de procesamiento: {tiempo[0]} horas')\n",
    "                        return\n",
    "\n",
    "                time.sleep(1)\n",
    "\n",
    "        tiempo_final = time.perf_counter()\n",
    "        tiempo = [round((tiempo_final - tiempo_inicial)/3600, 2)]\n",
    "        fecha = [date.today().strftime('%d-%m-%Y')]\n",
    "\n",
    "        lista_fallidos_purgada = []\n",
    "        for n in lista_fallidos:\n",
    "            if int(n) < indi:\n",
    "                lista_fallidos_purgada.append(n)\n",
    "\n",
    "        with open('./backups/fallidos.csv', mode='w', newline='') as archivo_csv:\n",
    "            escritor = csv.writer(archivo_csv)\n",
    "            escritor.writerow(lista_fallidos_purgada)\n",
    "        with open('./backups/en_proceso.csv', mode='w', newline='') as archivo_csv:\n",
    "            escritor = csv.writer(archivo_csv)\n",
    "            escritor.writerow([None])   # Se marca flag de proceso finalizado\n",
    "\n",
    "        with open('./backups/ultima_act_fecha.csv', mode='w', newline='') as archivo_csv:\n",
    "            escritor = csv.writer(archivo_csv)\n",
    "            escritor.writerow(fecha)\n",
    "        with open('./backups/ultima_act_tiempo.csv', mode='w', newline='') as archivo_csv:\n",
    "            escritor = csv.writer(archivo_csv)\n",
    "            escritor.writerow(tiempo)\n",
    "\n",
    "        # Al ser primera ejecución, en este paso también se crea una lista vacia de IDs procesados (pasados a DF),\n",
    "        # y un DF para la base general y se exportan a csv, que luego serán utilizados por la función de actualización de bases.\n",
    "\n",
    "        procesados = []\n",
    "\n",
    "        with open('./backups/procesados.csv', mode='w', newline='') as archivo_csv:\n",
    "            escritor = csv.writer(archivo_csv)\n",
    "            escritor.writerow(procesados)\n",
    "\n",
    "        df_resultados = pd.DataFrame({\n",
    "            'id':[],\n",
    "            'nombre':[],\n",
    "            'fecha':[],\n",
    "            'hora':[],\n",
    "            'metros':[],\n",
    "            'suelo':[],\n",
    "            'condicion':[],\n",
    "            'posicion':[],\n",
    "            'numero':[],\n",
    "            'competidor':[],\n",
    "            'diferencia':[],\n",
    "            'peso_jockey':[],\n",
    "            'peso_caballo':[],\n",
    "            'pagaria':[]\n",
    "            })\n",
    "        df_resultados.to_csv('./backups/df_resultados.csv', index=False)\n",
    "\n",
    "        print('* Descarga finalizada *')\n",
    "        print('Carreras descargadas:', exitosos)\n",
    "        print('Páginas no encontradas:', fallidos)\n",
    "        print('ID máximo encontrado:', indi)\n",
    "        print(f'Tiempo de procesamiento: {tiempo[0]} horas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_c():\n",
    "  \"\"\"Función integradora para comprobar primero interrupciones de ejecución anteriores y corregir si hace falta,\n",
    "  y posteriormente para iniciar el proceso de descarga de nuevas carreras y/o reintento de fallidos\"\"\"\n",
    "\n",
    "  directorios, lista_fallidos, fecha, tiempo, min_existente, max_existente, lista_existentes, en_proceso = status()\n",
    "\n",
    "  if en_proceso == True:\n",
    "    print('Ejecución anterior interrumpida. Iniciando comprobación de errores...')\n",
    "    time.sleep(0.2)\n",
    "    lista_fallidos = comprobar_errores(lista_existentes, min_existente, max_existente)\n",
    "    with open('./backups/en_proceso.csv', mode='w', newline='') as archivo_csv:\n",
    "            escritor = csv.writer(archivo_csv)\n",
    "            escritor.writerow([None])\n",
    "\n",
    "\n",
    "  descargar_carreras(directorios, lista_fallidos, fecha, tiempo, min_existente, max_existente, lista_existentes)\n",
    "\n",
    "  print('\\nPresione [Enter] para volver al menú principal')\n",
    "  time.sleep(0.2)\n",
    "  input('')\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para actualizar la base de resultados y almacenarla en CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer datos generales de la carrera\n",
    "\n",
    "def ext_datos_generales(txtcarrera):\n",
    "  \"\"\"Esta función toma como parámetro un archivo txt con datos de una carrera, generado en la función descargar_carrera(),\n",
    "  y, por medio de referencias en el texto del archivo, identifica los datos generales de la carrera y almacena en una\n",
    "  variable los datos que luego se utilizarán. Los datos generales corresponden a la fecha, la hora, la distancia de la pista y su estado,\n",
    "  entre otros.\n",
    "  \"\"\"\n",
    "\n",
    "  contador1 = 0\n",
    "  contador2 = 0\n",
    "\n",
    "  for i in range(len(txtcarrera)):\n",
    "    if txtcarrera[i] =='-':\n",
    "      contador1 = i+2\n",
    "      break\n",
    "\n",
    "  carrera_dg = txtcarrera[contador1:]\n",
    "\n",
    "  test = 0\n",
    "  for i in range(len(carrera_dg)):\n",
    "\n",
    "    if carrera_dg[i].isdigit() == True or carrera_dg[i] == ':':\n",
    "      test +=1\n",
    "    else:\n",
    "      test = 0\n",
    "\n",
    "    if test == 6:\n",
    "      contador2 = i-6\n",
    "      break\n",
    "\n",
    "  carrera_dg = carrera_dg[:contador2]\n",
    "  carrera_dg = carrera_dg.replace(' VIDEO FECHA HORA DISTANCIA PISTA TIEMPO CONDICIóN PREMIOS','')\n",
    "  carrera_dg = carrera_dg.replace('| ','')\n",
    "\n",
    "  return carrera_dg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datos_gen(dg_carrera):\n",
    "  \"\"\"La función toma el archivo generado anteriormente, e identifica y separa la información útil en las correspondientes\n",
    "  variables.\n",
    "  \"\"\"\n",
    "  contador = 0\n",
    "  test = 0\n",
    "\n",
    "  for i in range(len(dg_carrera)):\n",
    "\n",
    "    if dg_carrera[i].isdigit() == True or dg_carrera[i] == '/':\n",
    "      test +=1\n",
    "    else:\n",
    "      test = 0\n",
    "\n",
    "    if test == 10:\n",
    "      contador = i-10\n",
    "      break\n",
    "\n",
    "  nombre = dg_carrera[:contador]\n",
    "  fecha, hora, metros, suelo, condicion = dg_carrera[contador:].strip().split()\n",
    "\n",
    "  return nombre, fecha, hora, metros, suelo, condicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ext_resultados(carrera):\n",
    "  \"\"\"Delimita el espacio en donde se encuentra la información de los resultados de la carrera, en el archivo txt pasado por\n",
    "  parámetro.\n",
    "  \"\"\"\n",
    "\n",
    "  x = re.search(r'Resultado ', carrera)\n",
    "  inicio = x.span()[1]+95 # sumando 95 se elimina la primera repeticion de los nombres de las columnas.\n",
    "\n",
    "  y = re.search(r' Datos del Ganador', carrera)\n",
    "  fin = y.span()[0]\n",
    "\n",
    "  extracto_1 = carrera[inicio:fin]\n",
    "  extracto_1 = extracto_1.replace(' POS.. NRO. COMPETIDOR TM DISTANCIA. JOCKEY CUIDADOR CABALLERIZA. PESO JOCKEY / CABALLO PAGARIA ',';')\n",
    "  extracto_1 = extracto_1.replace('FB ','')\n",
    "  extracto_1 = extracto_1.replace('FB-S ','')\n",
    "  extracto_1 = extracto_1.split(';')\n",
    "\n",
    "  return extracto_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_resultado(fila):\n",
    "  \"\"\"Se recorre cada elemento de la lista obtenida en la función ext_resultados y se seccionan y almacenan\n",
    "  los datos en las variables necesarias, para luego ser agregados al DF de resultados (y por ende al archivo CSV de respaldo)\n",
    "  en la función integradora a_b().\n",
    "  \"\"\"\n",
    "\n",
    "  diferencias = ['PRIMER PUESTO','VENTAJA MINIMA','1 HOCICO','1/2 CABEZA','1 CABEZA','1/2 PESCUEZO','1 PESCUEZO','1/2 CUERPO','3/4 CUERPO','1 CUERPO','1 1/2 CUERPO','2 CUERPO','2 1/2 CUERPO','3 CUERPO','3 1/2 CUERPO','4 CUERPO','4 1/2 CUERPO','5 CUERPO','5 1/2 CUERPO','6 CUERPO','6 1/2 CUERPO','7 CUERPO','7 1/2 CUERPO','8 CUERPO','8 1/2 CUERPO','9 CUERPO','9 1/2 CUERPO','10 CUERPO','10 1/2 CUERPO','11 CUERPO','11 1/2 CUERPO','12 CUERPO','12 1/2 CUERPO','13 CUERPO','13 1/2 CUERPO','14 CUERPO','14 1/2 CUERPO','15 CUERPO','15 1/2 CUERPO','16 CUERPO','16 1/2 CUERPO','17 CUERPO','17 1/2 CUERPO','18 CUERPO','18 1/2 CUERPO','19 CUERPO','19 1/2 CUERPO','20 CUERPO','20 1/2 CUERPO','21 CUERPO','21 1/2 CUERPO','22 CUERPO','22 1/2 CUERPO','23 CUERPO','23 1/2 CUERPO','24 CUERPO','24 1/2 CUERPO','25 CUERPO','25 1/2 CUERPO','26 CUERPO','26 1/2 CUERPO','27 CUERPO','27 1/2 CUERPO','28 CUERPO','28 1/2 CUERPO','29 CUERPO','29 1/2 CUERPO','30 CUERPO','SIN APRECIACION','RODO','DESMONTO','DIST.MOLESTAR','DIST.DOPING']\n",
    "\n",
    "  cont1 = 0\n",
    "  for c in range(len(fila)):\n",
    "    if fila[c] == ' ':\n",
    "      cont1 += 1\n",
    "    if cont1 == 2:\n",
    "      corte1 = c\n",
    "      break\n",
    "\n",
    "  corte_pos1 = fila[0:corte1]\n",
    "  posicion, numero = corte_pos1.split()\n",
    "  fila = fila[corte1+1:]\n",
    "\n",
    "  if posicion == 'RET':\n",
    "    competidor = fila\n",
    "    diferencia = np.nan\n",
    "    peso_jockey = np.nan\n",
    "    peso_caballo = np.nan\n",
    "    pagaria = np.nan\n",
    "\n",
    "  else:\n",
    "      # buscar donde alguna de las palabras/frases de la lista \"diferencias\" y al encontrarla identificar el indice en el cual inicia dicha frase o palabra.\n",
    "      patron = '|'.join(re.escape(palabra) for palabra in diferencias) # crea un patrón para buscar con el modulo regex\n",
    "      match = re.search(patron, fila)  # Buscar la  coincidencia de cualquier palabra en la lista diferencias\n",
    "\n",
    "      if match:         # Si encuentra una coincidencia, devuelve el índice de inicio y fin\n",
    "        corte2 = match.span()[0]\n",
    "        diferencia = match.group()\n",
    "        competidor = fila[:corte2-1]\n",
    "      else:\n",
    "        diferencia = 'revisar error'\n",
    "        competidor = 'revisar error'\n",
    "\n",
    "      cont3 = 0\n",
    "      for i in range(len(fila)-1, 0, -1):\n",
    "        if fila[i] == ' ':\n",
    "            cont3 += 1\n",
    "        if cont3 == 2:\n",
    "            corte3 = i\n",
    "            break\n",
    "\n",
    "      corte_pos2 = fila[corte3+1:]\n",
    "      pesos, pagaria = corte_pos2.split()\n",
    "\n",
    "      try:\n",
    "        peso_jockey, peso_caballo = pesos.split('/')\n",
    "      except ValueError:\n",
    "        pesos = pagaria\n",
    "        pagaria = np.nan\n",
    "        peso_jockey, peso_caballo = pesos.split('/')\n",
    "\n",
    "  return posicion, numero, competidor, diferencia, peso_jockey, peso_caballo, pagaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_b():\n",
    "  \"\"\"Función integradora para actualizar la base de datos con la nueva información descargada.\n",
    "  \"\"\"\n",
    "  # 1. se importan los csv con las listas de ID procesados y el df principal.\n",
    "  with open('./backups/procesados.csv', mode='r', newline='') as archivo_csv:\n",
    "        lector = csv.reader(archivo_csv)\n",
    "        procesados = next(lector)\n",
    "\n",
    "  df_resultados = pd.read_csv('./backups/df_resultados.csv', parse_dates=['fecha'])\n",
    "\n",
    "  # 2. Compara el largo de la lista ID procesados y la cantidad de archivos .txt de carreras. Si hay más archivos que ID procesados,\n",
    "  # se procede a realizar la actualización de la base de datos con aquellos archivos nuevos. En caso de no haber diferencia, se informa\n",
    "  # al usuario y sale de la función.\n",
    "\n",
    "  carreras = os.listdir('./backups/carreras')\n",
    "\n",
    "  if len(carreras) > len(procesados):\n",
    "      print('Actualizando base de datos...')\n",
    "      time.sleep(1)\n",
    "\n",
    "      # recorre el directorio de carreras, y procesa aquellos archivos que no figuran en la lista 'procesados'.\n",
    "\n",
    "      for id in carreras:\n",
    "          if id in procesados:\n",
    "              continue # continua al siguiente archivo sin hacer nada más.\n",
    "\n",
    "          else:\n",
    "              print(id)\n",
    "              procesados.append(id)\n",
    "              idc = id.replace('.txt','')\n",
    "\n",
    "              with open(f'./backups/carreras/{id}', 'r', encoding='utf-8') as arch:\n",
    "                carrera = arch.read()\n",
    "\n",
    "              datos_generales = ext_datos_generales(carrera)\n",
    "              nombre, fecha, hora, metros, suelo, condicion = preparar_datos_gen(datos_generales)\n",
    "\n",
    "              resultado_raw = ext_resultados(carrera)\n",
    "\n",
    "              for fila in resultado_raw:\n",
    "                posicion, numero, competidor, diferencia, peso_jockey, peso_caballo, pagaria = preparar_resultado(fila)\n",
    "\n",
    "                # Se formatea una nueva línea para agregar al DF de resultados\n",
    "                nueva_fila = pd.DataFrame({\n",
    "                                        'id':[idc],\n",
    "                                        'nombre':[nombre],\n",
    "                                        'fecha':[fecha],\n",
    "                                        'hora':[hora],\n",
    "                                        'metros':[metros],\n",
    "                                        'suelo':[suelo],\n",
    "                                        'condicion':[condicion],\n",
    "                                        'posicion':[posicion],\n",
    "                                        'numero':[numero],\n",
    "                                        'competidor':[competidor],\n",
    "                                        'diferencia':[diferencia],\n",
    "                                        'peso_jockey':[peso_jockey],\n",
    "                                        'peso_caballo':[peso_caballo],\n",
    "                                        'pagaria':[pagaria]\n",
    "                                        })\n",
    "\n",
    "                nueva_fila['fecha'] = pd.to_datetime(nueva_fila['fecha'], format='%d/%m/%Y')\n",
    "                nueva_fila['hora'] = pd.to_datetime(nueva_fila['hora'], format='%H:%M').dt.time\n",
    "\n",
    "                df_resultados = pd.concat([df_resultados, nueva_fila], ignore_index=True)\n",
    "\n",
    "      #una vez concluida la actualización, se exporta df y lista de procesados a csv.\n",
    "      with open('./backups/procesados.csv', mode='w', newline='') as archivo_csv:\n",
    "            escritor = csv.writer(archivo_csv)\n",
    "            escritor.writerow(procesados)\n",
    "\n",
    "      df_resultados.to_csv('./backups/df_resultados.csv', index=False)\n",
    "\n",
    "      print('Actualización de base de datos finalizada')\n",
    "\n",
    "  else:\n",
    "      print('La base de datos está actualizada. Omitiendo paso.')\n",
    "      time.sleep(1)\n",
    "\n",
    "  print('\\nPresione [Enter] para volver al menú principal')\n",
    "  time.sleep(1)\n",
    "  input('')\n",
    "  print('')\n",
    "\n",
    "  return df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para actualizar rankings de jockeys y cuidadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descargar_rankings():\n",
    "  \"\"\"Se conecta a la URL indicada y mediante parseo del html, recupera la información actualizada de los rankings de jockeys y cuidadores.\n",
    "  \"\"\"\n",
    "\n",
    "  url = f\"https://www.palermo.com.ar/es/turf/ranking-de-jockeys-y-cuidadores\"\n",
    "  print('Descargando última versión del ranking de jockeys y cuidadores...')\n",
    "  print(url)\n",
    "  response = requests.get(url)\n",
    "  response.encoding = 'utf-8'\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "  texto_visible = soup.get_text(separator=' ', strip=True)\n",
    "\n",
    "  with open(f'./backups/rankings.txt', 'w', encoding='utf-8') as file:\n",
    "    file.write(texto_visible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_rankings():\n",
    "  \"\"\"Se crean DFs vacíos, para luego ser poblados por la información actualizada\n",
    "  \"\"\"\n",
    "\n",
    "  df_jockeys = pd.DataFrame({\n",
    "              'posicion':[],\n",
    "              'nombre':[],\n",
    "              'corr':[],\n",
    "              '1ro':[],\n",
    "              '2do':[],\n",
    "              '3ro':[],\n",
    "              '4to':[],\n",
    "              '5to':[],\n",
    "              'EF%_1':[],\n",
    "              'EF%_2al5':[]\n",
    "          })\n",
    "\n",
    "  df_cuidadores = pd.DataFrame({\n",
    "              'posicion':[],\n",
    "              'nombre':[],\n",
    "              'corr':[],\n",
    "              '1ro':[],\n",
    "              '2do':[],\n",
    "              '3ro':[],\n",
    "              '4to':[],\n",
    "              '5to':[],\n",
    "              'EF%_1':[],\n",
    "              'EF%_2al5':[]\n",
    "          })\n",
    "\n",
    "  with open(f'./backups/rankings.txt', 'r', encoding='utf-8') as arch:\n",
    "    rankings = arch.read()\n",
    "\n",
    "  rankings_1 = rankings[208:-1461]\n",
    "\n",
    "  x = re.search(r' POS CUIDADOR CORR 1ro 2do 3ro 4to 5to EF% 1 EF% 2 al 5 ', rankings_1)\n",
    "  corte_i = x.span()[0]\n",
    "  corte_f = x.span()[1]\n",
    "\n",
    "  ranking_jockeys = rankings_1[:corte_i]\n",
    "  ranking_cuidadores = rankings_1[corte_f:]\n",
    "\n",
    "  return ranking_cuidadores, ranking_jockeys, df_cuidadores, df_jockeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_ranking(ranking_original, df):\n",
    "  \"\"\"Utilizando los rankings retornados en la función anterior, se completan los dfs vacíos.\n",
    "\n",
    "  Argumentos:\n",
    "\n",
    "  ranking_original -- ranking_jockeys o ranking_cuidadores\n",
    "  df -- df_jockeys o df_cuidadores\n",
    "  \"\"\"\n",
    "\n",
    "  for p in range(1,16):\n",
    "\n",
    "    posicion = p\n",
    "\n",
    "    patron = rf'{p} [A-Z]'\n",
    "    rdo_busqueda = re.search(patron, ranking_original)\n",
    "    corte_1 = rdo_busqueda.span()[0]\n",
    "\n",
    "    if p < 10:\n",
    "      ranking_recorte = ranking_original[corte_1+2:]\n",
    "    else:\n",
    "      ranking_recorte = ranking_original[corte_1+3:]\n",
    "\n",
    "    chars = string.ascii_uppercase + ' ' + '(' + ')'\n",
    "    corte_2 = 0\n",
    "    for c in range(len(ranking_recorte)):\n",
    "          if ranking_recorte[c] in chars:\n",
    "            continue\n",
    "          else:\n",
    "            nombre = ranking_recorte[:c-1]\n",
    "            corte_2 = c\n",
    "            break\n",
    "    ranking_recorte = ranking_recorte[corte_2:]\n",
    "\n",
    "    if p < 15:\n",
    "      patron = rf'{p+1} [A-Z]'\n",
    "      rdo_busqueda = re.search(patron, ranking_recorte)\n",
    "      corte_3 = rdo_busqueda.span()[0]-1\n",
    "      ranking_recorte = ranking_recorte[:corte_3]\n",
    "\n",
    "    valor1, valor2, valor3, valor4, valor5, valor6, valor7, valor8 = ranking_recorte.split()\n",
    "\n",
    "    valor7 = valor7.replace(',','.')\n",
    "    valor8 = valor8.replace(',','.')\n",
    "\n",
    "    nueva_fila = pd.DataFrame({\n",
    "                               'posicion':[posicion],\n",
    "                                 'nombre':[nombre],\n",
    "                                   'corr':[valor1],\n",
    "                                    '1ro':[valor2],\n",
    "                                    '2do':[valor3],\n",
    "                                    '3ro':[valor4],\n",
    "                                    '4to':[valor5],\n",
    "                                    '5to':[valor6],\n",
    "                                  'EF%_1':[valor7],\n",
    "                               'EF%_2al5':[valor8]\n",
    "                              })\n",
    "\n",
    "    df = pd.concat([df, nueva_fila], ignore_index=True)\n",
    "\n",
    "  df['posicion'] = df['posicion'].astype(int)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_r():\n",
    "  \"\"\"Función integradora para actualizar los archivos de respaldo de rankings.\n",
    "  \"\"\"\n",
    "\n",
    "  if os.path.isfile('./backups/df_jockeys.csv'):\n",
    "\n",
    "    with open('./backups/fecha_rankings.csv', mode='r', newline='') as archivo_csv:\n",
    "      lector = csv.reader(archivo_csv)\n",
    "      fecha_rankings = next(lector)\n",
    "\n",
    "    opcion = input(f'Los rankings se actualizaron por última vez el {fecha_rankings}. ¿Desea actualizarlos ahora? (s/n)')\n",
    "    time.sleep(1)\n",
    "\n",
    "    if opcion.lower() == 'n':\n",
    "       print('Omitiendo...')\n",
    "       return\n",
    "\n",
    "  print('Actualizando rankings...')\n",
    "  time.sleep(1)\n",
    "  descargar_rankings()\n",
    "\n",
    "  ranking_cuidadores, ranking_jockeys, df_cuidadores, df_jockeys = generar_rankings()\n",
    "  df_jockeys = actualizar_ranking(ranking_jockeys, df_jockeys)\n",
    "  df_cuidadores = actualizar_ranking(ranking_cuidadores, df_cuidadores)\n",
    "\n",
    "  df_jockeys.to_csv('./backups/df_jockeys.csv')\n",
    "  df_cuidadores.to_csv('./backups/df_cuidadores.csv')\n",
    "  fecha_rankings = [date.today().strftime('%d-%m-%Y')]\n",
    "\n",
    "  with open('./backups/fecha_rankings.csv', mode='w', newline='') as archivo_csv:\n",
    "    escritor = csv.writer(archivo_csv)\n",
    "    escritor.writerow(fecha_rankings)\n",
    "\n",
    "  print('Actualización de rankings finalizada.')\n",
    "  time.sleep(1)\n",
    "  print('\\nPresione [Enter] para volver al menú principal')\n",
    "  input('')\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para leer un programa de carreras dado, ubicado en \"pdf_path\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escanear_programa(pdf_path):\n",
    "  \"\"\"Se crea la Clase Dfreuniones para luego instanciar todos los dataframe donde se almacenarán los datos de\n",
    "  cada próxima carrera del programa analizado, asi como una lista asociada a cada uno conteniendo el número de carrera y\n",
    "  la distancia en metros. También se crea una variable conteniendo la fecha del programa analizado y el número de reunión,\n",
    "  para utilizarlo posteriormente en la presentanción del resultado.\n",
    "\n",
    "  Para recorrer el PDF se utiliza la búsqueda por coordenadas, es decir qué, al encontrarse cierta frase o texto, se\n",
    "  traza un rectángulo delimitador y se utilizan dichas coordenadas para buscar otros textos utilizando esta referencia para\n",
    "  ubicarlos.\n",
    "  \"\"\"\n",
    "\n",
    "  class DFreuniones:\n",
    "    def __init__(self):\n",
    "         self.dataframe = pd.DataFrame(columns=['chaquetilla', 'competidor', 'jockey', 'edad_caballo'])\n",
    "\n",
    "    def obtener_dataframe(self):\n",
    "        return self.dataframe\n",
    "\n",
    "  dfp_base = DFreuniones()\n",
    "\n",
    "  dfp_1 = dfp_base.obtener_dataframe()\n",
    "  # En las listas datos_carrera_#, se almacena el número de carrera y posteriormente se agregará la distancia en metros.\n",
    "  # Los datos se agregan en ese orden, y se accederá luego a ellos a través de sus índices.\n",
    "  datos_carrera_1 = ['1ª Carrera']\n",
    "\n",
    "  dfp_2 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_2 = ['2ª Carrera']\n",
    "\n",
    "  dfp_3 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_3 = ['3ª Carrera']\n",
    "\n",
    "  dfp_4 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_4 = ['4ª Carrera']\n",
    "\n",
    "  dfp_5 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_5 = ['5ª Carrera']\n",
    "\n",
    "  dfp_6 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_6 = ['6ª Carrera']\n",
    "\n",
    "  dfp_7 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_7 = ['7ª Carrera']\n",
    "\n",
    "  dfp_8 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_8 = ['8ª Carrera']\n",
    "\n",
    "  dfp_9 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_9 = ['9ª Carrera']\n",
    "\n",
    "  dfp_10 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_10 = ['10ª Carrera']\n",
    "\n",
    "  dfp_11 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_11 = ['11ª Carrera']\n",
    "\n",
    "  dfp_12 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_12 = ['12ª Carrera']\n",
    "\n",
    "  dfp_13 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_13 = ['13ª Carrera']\n",
    "\n",
    "  dfp_14 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_14 = ['14ª Carrera']\n",
    "\n",
    "  dfp_15 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_15 = ['15ª Carrera']\n",
    "\n",
    "  dfp_16 = dfp_base.obtener_dataframe()\n",
    "  datos_carrera_16 = ['16ª Carrera']\n",
    "\n",
    "  doc = fitz.open(pdf_path)\n",
    "\n",
    "  cantidad_carreras = 0\n",
    "  meses = ['Enero','Febrero','Marzo','Abril','Mayo','Junio','Julio','Agosto','Septiembre','Octubre','Noviembre','Diciembre']\n",
    "\n",
    "  # Iterar sobre cada página\n",
    "  for pagina_num in range(doc.page_count):\n",
    "    pagina = doc.load_page(pagina_num)  # Cargar la página\n",
    "    texto = pagina.get_text(\"text\")  # Obtener todo el texto de la página\n",
    "\n",
    "    # Fórmula para pasar de milímetros a puntos PDF: (mm / 25.4) * 72\n",
    "\n",
    "    if pagina_num == 0:\n",
    "      for mes in meses:\n",
    "        if re.search(mes, texto):\n",
    "          coordenadas_mes = pagina.search_for(mes)\n",
    "          coordenadas_mes = coordenadas_mes[0]\n",
    "\n",
    "          # fecha que se utilizará para todas las carreras del día, al emitir el reporte.\n",
    "          reunion_fecha = pagina.get_text(\"text\", clip=fitz.Rect(coordenadas_mes.x0 - 212.60, coordenadas_mes.y0, coordenadas_mes.x1 + 73.7, coordenadas_mes.y1)).rstrip()\n",
    "\n",
    "\n",
    "    for c in range(1,17):\n",
    "      carrera = ''\n",
    "      if c == 1:\n",
    "        carrera = fr'\\b{c}ª Carrera\\b'\n",
    "      else:\n",
    "        carrera = fr'\\b{c} ª Carrera\\b'\n",
    "\n",
    "      if re.search(carrera, texto):\n",
    "        cantidad_carreras += 1\n",
    "        carrera = carrera.replace('\\\\b', '')\n",
    "\n",
    "        #detectar coordenadas de la numeración de cada carrera:\n",
    "        coord_nro_carrera = pagina.search_for(carrera)\n",
    "        coord_nro_carrera = coord_nro_carrera[0]\n",
    "\n",
    "        #detectar coordenadas de la palabra \"metros\" para luego extraer la longitud de la pista de la carrera analizada.\n",
    "        coord_metros = pagina.search_for(\"metros\", clip=fitz.Rect(coord_nro_carrera.x0 + 76.53, coord_nro_carrera.y0 - 14.17, coord_nro_carrera.x1 + 413.86, coord_nro_carrera.y1 + 10.49))\n",
    "        coord_metros = coord_metros[0]\n",
    "\n",
    "        metros = pagina.get_text(\"text\", clip=fitz.Rect(coord_metros.x0 - 31.18, coord_metros.y0, coord_metros.x1 - 48.19, coord_metros.y1)).rstrip()\n",
    "\n",
    "        # Búsqueda de las coordenadas de la palabra \"Caballeriza\", debajo de la numeración de la carrera,\n",
    "        # para ubicar donde comienza el cuadro con los datos de los competidores inscriptos.\n",
    "\n",
    "        coord_caballeriza = pagina.search_for(\"Caballeriza\", clip=fitz.Rect(coord_nro_carrera.x0, coord_nro_carrera.y0, coord_nro_carrera.x1, coord_nro_carrera.y1 + 159))\n",
    "        coord_caballeriza = coord_caballeriza[0]\n",
    "\n",
    "        # Una vez encontradas las coordenadas de \"Caballeriza\", se utilizan estas como referencia para encontrar las coordenadas del encabezado del campo \"Nº\"\n",
    "\n",
    "        coord_Nro = pagina.search_for(\"Nº\", clip=fitz.Rect(coord_caballeriza.x0, coord_caballeriza.y0, coord_caballeriza.x1 + 97, coord_caballeriza.y1))\n",
    "        coord_Nro = coord_Nro[0]\n",
    "\n",
    "        # Luego de detectar las coordinadas de \"Nº\", se buscan los números de chaquetilla de los primeros 2 participantes (1 y 2),\n",
    "        # para calcular la distancia a la cual se encuentra cada registro, ya que puede variar de carrera a carrera (fila mas ancha o más fina)\n",
    "        # Para buscar estos numeros, se prepara un rectangulo hacia abajo de \"Nº\" tomando como referncia los casos en donde las columnas son las más anchas.\n",
    "\n",
    "        coord_1 = pagina.search_for(\"1\", clip=fitz.Rect(coord_Nro.x0 - 4.25, coord_Nro.y0, coord_Nro.x1 + 4.25, coord_Nro.y1 + 56.7))\n",
    "        coord_1 = coord_1[0]\n",
    "\n",
    "        coord_2 = pagina.search_for(\"2\", clip=fitz.Rect(coord_Nro.x0 - 4.25, coord_Nro.y0, coord_Nro.x1 + 4.25, coord_Nro.y1 + 56.7))\n",
    "        coord_2 = coord_2[0]\n",
    "\n",
    "        # A continuación se calcula la diferencia entre ambas distancias (y1 e y0) de cada nro detectado, para calcular\n",
    "        # el valor de \"step\" que se va utilizar para ir recorriendo las filas hacia abajo y tomando los datos\n",
    "        # de cada competidor. Tambien se almacenan los valores que tomará el ancho de cada recuadro.\n",
    "\n",
    "        step_y = coord_2.y0 - coord_1.y0\n",
    "        x0 = coord_Nro.x0 - 4.25\n",
    "        x1 = coord_Nro.x1 + 4.25\n",
    "        coords = fitz.Rect(x0, coord_1.y0, x1, coord_1.y1)  # coordenadas iniciales por donde se comenzará la búsqueda de competidores en la tabla\n",
    "        continuar_bucle = True # esta variable indicará al bucle while cuando detenerse debido a que ya se procesó el último competidor de la carrera analizada\n",
    "\n",
    "        print(carrera)\n",
    "\n",
    "        while continuar_bucle == True:\n",
    "          chaquetilla = pagina.get_text(\"text\", clip=coords).rstrip()\n",
    "          competidor_raw = pagina.get_text(\"text\", clip=fitz.Rect(coords.x1, coords.y0, coords.x1+110, coords.y1)).rstrip()\n",
    "\n",
    "          # se limpia el campo de competidor para dejar solo el nombre y descartar otros datos\n",
    "\n",
    "          competidor_list = competidor_raw.strip().split()\n",
    "          competidor = ''\n",
    "\n",
    "          for i in range(len(competidor_list)):\n",
    "\n",
    "            try:\n",
    "              float(competidor_list[i])\n",
    "            except:\n",
    "              continue\n",
    "            else:\n",
    "              competidor_list.remove(competidor_list[i])\n",
    "\n",
    "          for e in competidor_list:\n",
    "            if competidor == '':\n",
    "              competidor = e\n",
    "            else:\n",
    "              competidor = competidor + ' ' + e\n",
    "\n",
    "          jockey = pagina.get_text(\"text\", clip=fitz.Rect(coords.x1+110, coords.y0, coords.x1+110+89.69, coords.y1)).rstrip().upper()\n",
    "          edad = pagina.get_text(\"text\", clip=fitz.Rect(coords.x1+110+101.59, coords.y0, coords.x1+110+89.69+20.3, coords.y1)).rstrip().upper()\n",
    "\n",
    "          # se comprueba que no se haya leido accidentalemente el color del pelaje junto con la edad, y se procede a limpiar si ese es el caso:\n",
    "\n",
    "          if len(edad) == 3:\n",
    "            edad = edad[2]\n",
    "          elif len(edad) == 2:\n",
    "            edad = edad[1]\n",
    "\n",
    "          nueva_fila = pd.DataFrame({\n",
    "                                        'chaquetilla':[chaquetilla],\n",
    "                                        'competidor':[competidor],\n",
    "                                        'jockey':[jockey],\n",
    "                                        'edad_caballo':[edad],\n",
    "                                        })\n",
    "\n",
    "          match c:\n",
    "            case (1):\n",
    "              dfp_1 = pd.concat([dfp_1, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_1) == 1:\n",
    "                datos_carrera_1.append(metros)\n",
    "            case (2):\n",
    "              dfp_2 = pd.concat([dfp_2, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_2) == 1:\n",
    "                datos_carrera_2.append(metros)\n",
    "            case (3):\n",
    "              dfp_3 = pd.concat([dfp_3, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_3) == 1:\n",
    "                datos_carrera_3.append(metros)\n",
    "            case (4):\n",
    "              dfp_4 = pd.concat([dfp_4, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_4) == 1:\n",
    "                datos_carrera_4.append(metros)\n",
    "            case (5):\n",
    "              dfp_5 = pd.concat([dfp_5, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_5) == 1:\n",
    "                datos_carrera_5.append(metros)\n",
    "            case (6):\n",
    "              dfp_6 = pd.concat([dfp_6, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_6) == 1:\n",
    "                datos_carrera_6.append(metros)\n",
    "            case (7):\n",
    "              dfp_7 = pd.concat([dfp_7, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_7) == 1:\n",
    "                datos_carrera_7.append(metros)\n",
    "            case (8):\n",
    "              dfp_8 = pd.concat([dfp_8, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_8) == 1:\n",
    "                datos_carrera_8.append(metros)\n",
    "            case (9):\n",
    "              dfp_9 = pd.concat([dfp_9, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_9) == 1:\n",
    "                datos_carrera_9.append(metros)\n",
    "            case (10):\n",
    "              dfp_10 = pd.concat([dfp_10, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_10) == 1:\n",
    "                datos_carrera_10.append(metros)\n",
    "            case (11):\n",
    "              dfp_11 = pd.concat([dfp_11, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_11) == 1:\n",
    "                datos_carrera_11.append(metros)\n",
    "            case (12):\n",
    "              dfp_12 = pd.concat([dfp_12, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_12) == 1:\n",
    "                datos_carrera_12.append(metros)\n",
    "            case (13):\n",
    "              dfp_13 = pd.concat([dfp_13, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_13) == 1:\n",
    "                datos_carrera_13.append(metros)\n",
    "            case (14):\n",
    "              dfp_14 = pd.concat([dfp_14, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_14) == 1:\n",
    "                datos_carrera_14.append(metros)\n",
    "            case (15):\n",
    "              dfp_15 = pd.concat([dfp_15, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_15) == 1:\n",
    "                datos_carrera_15.append(metros)\n",
    "            case (16):\n",
    "              dfp_16 = pd.concat([dfp_16, nueva_fila], ignore_index=True)\n",
    "              if len(datos_carrera_16) == 1:\n",
    "                datos_carrera_16.append(metros)\n",
    "\n",
    "          # ahora se comprueba si la siguiente linea contiene otro competidor. En dicho caso actualiza el rectangulo \"coords\"\n",
    "          # y continua el bucle. Caso contrario, se cambia el valor de la var. continuar bucle para detener el proceso y pasar a la siguiente carrera\n",
    "\n",
    "          validacion = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16']\n",
    "          comprobacion = pagina.get_text(\"text\", clip=fitz.Rect(coords.x0, coords.y0+step_y, coords.x1, coords.y1+step_y)).rstrip().strip()\n",
    "\n",
    "          if comprobacion in validacion:\n",
    "              coords = fitz.Rect(coords.x0, coords.y0+step_y, coords.x1, coords.y1+step_y)\n",
    "          else:\n",
    "              continuar_bucle = False\n",
    "\n",
    "  return reunion_fecha, cantidad_carreras, dfp_1, datos_carrera_1, dfp_2, datos_carrera_2, dfp_3, datos_carrera_3, dfp_4, datos_carrera_4, dfp_5, datos_carrera_5, dfp_6, datos_carrera_6, dfp_7, datos_carrera_7, dfp_8, datos_carrera_8, dfp_9, datos_carrera_9, dfp_10, datos_carrera_10, dfp_11, datos_carrera_11, dfp_12, datos_carrera_12, dfp_13, datos_carrera_13, dfp_14, datos_carrera_14, dfp_15, datos_carrera_15, dfp_16, datos_carrera_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_p():\n",
    "  \"\"\"Función integradora para escanear programas de futuras carreras\n",
    "  \"\"\"\n",
    "\n",
    "  print('Programas/rutas disponibles:')\n",
    "\n",
    "  for f in os.listdir('./calendario'):\n",
    "    print(f'./calendario/{f}')\n",
    "\n",
    "  programa = input('Copie y pegue la ruta del programa a escanear del listado anterior:')\n",
    "\n",
    "  reunion_fecha, cantidad_carreras, dfp_1, datos_carrera_1, dfp_2, datos_carrera_2, dfp_3, datos_carrera_3, dfp_4, datos_carrera_4, dfp_5, datos_carrera_5, dfp_6, datos_carrera_6, dfp_7, datos_carrera_7, dfp_8, datos_carrera_8, dfp_9, datos_carrera_9, dfp_10, datos_carrera_10, dfp_11, datos_carrera_11, dfp_12, datos_carrera_12, dfp_13, datos_carrera_13, dfp_14, datos_carrera_14, dfp_15, datos_carrera_15, dfp_16, datos_carrera_16 = escanear_programa(programa)\n",
    "\n",
    "  print(f'{reunion_fecha}')\n",
    "  print(f'Se correrán {cantidad_carreras} carreras en esta reunión.')\n",
    "  print('\\nElija a continuación el nro. de carrera deseado para ver la información:')\n",
    "\n",
    "  while True:\n",
    "    carrera = input(f'Ingrese un valor del 1 al {cantidad_carreras} (total de carreras del programa), o presione enter para volver al menú principal')\n",
    "    time.sleep(0.2)\n",
    "\n",
    "    if carrera == '':\n",
    "      break\n",
    "\n",
    "    if carrera.isdigit():\n",
    "        carrera = int(carrera)\n",
    "        if carrera > cantidad_carreras:\n",
    "          print('El número ingresado excede la cantidad de carreras del programa.')\n",
    "        else:\n",
    "          if carrera == 1:\n",
    "            print(f'\\nLa {datos_carrera_1[0]} será de {datos_carrera_1[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_1)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 2:\n",
    "            print(f'\\nLa {datos_carrera_2[0]} será de {datos_carrera_2[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_2)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 3:\n",
    "            print(f'\\nLa {datos_carrera_3[0]} será de {datos_carrera_3[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_3)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 4:\n",
    "            print(f'\\nLa {datos_carrera_4[0]} será de {datos_carrera_4[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_4)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 5:\n",
    "            print(f'\\nLa {datos_carrera_5[0]} será de {datos_carrera_5[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_5)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 6:\n",
    "            print(f'\\nLa {datos_carrera_6[0]} será de {datos_carrera_6[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_6)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 7:\n",
    "            print(f'\\nLa {datos_carrera_7[0]} será de {datos_carrera_7[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_7)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 8:\n",
    "            print(f'\\nLa {datos_carrera_8[0]} será de {datos_carrera_8[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_8)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 9:\n",
    "            print(f'\\nLa {datos_carrera_9[0]} será de {datos_carrera_9[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_9)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 10:\n",
    "            print(f'\\nLa {datos_carrera_10[0]} será de {datos_carrera_10[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_10)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 11:\n",
    "            print(f'\\nLa {datos_carrera_11[0]} será de {datos_carrera_11[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_11)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 12:\n",
    "            print(f'\\nLa {datos_carrera_12[0]} será de {datos_carrera_12[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_12)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 13:\n",
    "            print(f'\\nLa {datos_carrera_13[0]} será de {datos_carrera_13[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_13)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 14:\n",
    "            print(f'\\nLa {datos_carrera_14[0]} será de {datos_carrera_14[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_14)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 15:\n",
    "            print(f'\\nLa {datos_carrera_15[0]} será de {datos_carrera_15[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_15)\n",
    "            input('Presione [Enter] para continuar')\n",
    "\n",
    "          elif carrera == 16:\n",
    "            print(f'\\nLa {datos_carrera_16[0]} será de {datos_carrera_16[1]} metros.')\n",
    "            print('\\nParticipantes:')\n",
    "            display(dfp_16)\n",
    "            input('Presione [Enter] para continuar')\n",
    "    else:\n",
    "      print('El valor ingresado no es un número.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para exportar las bases de datos a archivos de Excel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_i():\n",
    "\n",
    "    fecha = datetime.now().date()\n",
    "\n",
    "    df_resultados = pd.read_csv(\"./backups/df_resultados.csv\")\n",
    "    df_jockeys = pd.read_csv(\"./backups/df_jockeys.csv\")\n",
    "    df_cuidadores = pd.read_csv(\"./backups/df_cuidadores.csv\")\n",
    "\n",
    "    print('\\nExportando base de resultados...')\n",
    "    df_resultados.to_excel(f\"./exports/base_resultados {fecha}.xlsx\", index=False)\n",
    "    print('Exportando ranking de jockeys...')\n",
    "    df_jockeys.to_excel(f\"./exports/ranking_jockeys {fecha}.xlsx\", index=False)\n",
    "    print('Exportando ranking de cuidadores...')\n",
    "    df_cuidadores.to_excel(f\"./exports/ranking_cuidadores {fecha}.xlsx\", index=False)\n",
    "    print('Proceso finalizado')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menú principal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu():\n",
    "\n",
    "    while True:\n",
    "        print('Turf Scrapping - Menú principal')\n",
    "        print('-------------------------------')\n",
    "        print('1) Descargar resultados')\n",
    "        print('2) Actualizar base de resultados')\n",
    "        print('3) Actualizar rankings de jockeys y cuidadores')\n",
    "        print('4) Escanear programa')\n",
    "        print('5) Exportar información a archivos Excel')\n",
    "        print('6) Salir')\n",
    "        time.sleep(0.2)\n",
    "        opcion = int((input('Ingresar opción: ')))\n",
    "\n",
    "        if opcion == 1:     # Se reconoce la opción ingresada y se ejecuta la función solicitada por el usuario.\n",
    "            d_c()\n",
    "        elif opcion == 2:\n",
    "            a_b()\n",
    "        elif opcion == 3:\n",
    "            a_r()\n",
    "        elif opcion == 4:\n",
    "            l_p()\n",
    "        elif opcion == 5:\n",
    "            e_i()\n",
    "        elif opcion == 6:\n",
    "            print('\\nSaliendo...')\n",
    "            time.sleep(0.15)\n",
    "            break\n",
    "        else:\n",
    "            print('\\nError: La opción ingresada no es válida. Intente nuevamente\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turf Scrapping - Menú principal\n",
      "-------------------------------\n",
      "1) Descargar resultados\n",
      "2) Actualizar base de resultados\n",
      "3) Actualizar rankings de jockeys y cuidadores\n",
      "4) Escanear programa\n",
      "5) Exportar información a archivos Excel\n",
      "6) Salir\n",
      "- Actualización de archivos -\n",
      "Actualmente existen 12146 ID's de carreras no encontrados\n",
      "* Paso omitido *\n",
      "- La última actualización tuvo lugar el día 11-01-2025, y el tiempo de procesamiento fue de 0.88 horas -\n",
      "Ingrese rango de ID's a buscar:\n",
      "* ID mínimo descargado: 193092 *\n",
      "* ID máximo descargado: 209985 *\n",
      "ID inicial: 209758\n",
      "ID final: 209786\n",
      "Comenzando actualización...\n",
      "Explorando nuevos ID's...\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209758\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209759\n",
      "ID 209759 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209760\n",
      "ID 209760 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209761\n",
      "ID 209761 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209762\n",
      "ID 209762 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209763\n",
      "ID 209763 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209764\n",
      "ID 209764 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209765\n",
      "ID 209765 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209766\n",
      "ID 209766 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209767\n",
      "ID 209767 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209768\n",
      "ID 209768 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209769\n",
      "ID 209769 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209770\n",
      "ID 209770 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209771\n",
      "ID 209771 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209772\n",
      "ID 209772 ya existente. Omitiendo..\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209773\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209774\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209775\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209776\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209777\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209778\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209779\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209780\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209781\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209782\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209783\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209784\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209785\n",
      "https://www.palermo.com.ar/es/turf/ver-carrera/209786\n",
      "* Actualización finalizada *\n",
      "Nuevas carreras descargadas: 0\n",
      "Carreras recuperadas (ex-fallidas): 13\n",
      "Páginas no encontradas: 2\n",
      "ID máximo encontrado: 209786\n",
      "Tiempo de procesamiento: 0.02 horas\n",
      "\n",
      "Presione [Enter] para volver al menú principal\n",
      "\n",
      "Turf Scrapping - Menú principal\n",
      "-------------------------------\n",
      "1) Descargar resultados\n",
      "2) Actualizar base de resultados\n",
      "3) Actualizar rankings de jockeys y cuidadores\n",
      "4) Escanear programa\n",
      "5) Exportar información a archivos Excel\n",
      "6) Salir\n",
      "Actualizando base de datos...\n",
      "209758.txt\n",
      "209773.txt\n",
      "209774.txt\n",
      "209777.txt\n",
      "209778.txt\n",
      "209779.txt\n",
      "209780.txt\n",
      "209781.txt\n",
      "209782.txt\n",
      "209783.txt\n",
      "209784.txt\n",
      "209785.txt\n",
      "209786.txt\n",
      "Actualización de base de datos finalizada\n",
      "\n",
      "Presione [Enter] para volver al menú principal\n",
      "\n",
      "Turf Scrapping - Menú principal\n",
      "-------------------------------\n",
      "1) Descargar resultados\n",
      "2) Actualizar base de resultados\n",
      "3) Actualizar rankings de jockeys y cuidadores\n",
      "4) Escanear programa\n",
      "5) Exportar información a archivos Excel\n",
      "6) Salir\n",
      "Actualizando rankings...\n",
      "Descargando última versión del ranking de jockeys y cuidadores...\n",
      "https://www.palermo.com.ar/es/turf/ranking-de-jockeys-y-cuidadores\n",
      "Actualización de rankings finalizada.\n",
      "\n",
      "Presione [Enter] para volver al menú principal\n",
      "\n",
      "Turf Scrapping - Menú principal\n",
      "-------------------------------\n",
      "1) Descargar resultados\n",
      "2) Actualizar base de resultados\n",
      "3) Actualizar rankings de jockeys y cuidadores\n",
      "4) Escanear programa\n",
      "5) Exportar información a archivos Excel\n",
      "6) Salir\n",
      "Programas/rutas disponibles:\n",
      "./calendario/programa_1.pdf\n",
      "./calendario/programa_2.pdf\n",
      "./calendario/programa_3.pdf\n",
      "./calendario/programa_4.pdf\n",
      "./calendario/programa_5.pdf\n",
      "1ª Carrera\n",
      "2 ª Carrera\n",
      "3 ª Carrera\n",
      "4 ª Carrera\n",
      "5 ª Carrera\n",
      "6 ª Carrera\n",
      "7 ª Carrera\n",
      "8 ª Carrera\n",
      "9 ª Carrera\n",
      "10 ª Carrera\n",
      "11 ª Carrera\n",
      "12 ª Carrera\n",
      "13 ª Carrera\n",
      "14 ª Carrera\n",
      "15 ª Carrera\n",
      "REUNION Nº 82  ◇  Lunes, 2 de Septiembre de 2024.\n",
      "Se correrán 15 carreras en esta reunión.\n",
      "\n",
      "Elija a continuación el nro. de carrera deseado para ver la información:\n",
      "\n",
      "La 10ª Carrera será de 1100 metros.\n",
      "\n",
      "Participantes:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chaquetilla",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "competidor",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "jockey",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "edad_caballo",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a7f1dab5-42ac-4493-b403-b0b673c20029",
       "rows": [
        [
         "0",
         " 1",
         "SUPER JANE",
         "ARMOHA LEOPOLDO M",
         "6"
        ],
        [
         "1",
         " 2",
         "LA TABLET DE PLATA",
         "GONZALEZ LUCAS F  4",
         "7"
        ],
        [
         "2",
         " 3",
         "BREEZA MANI",
         "ORTEGA PAVON EDUARDO",
         "6"
        ],
        [
         "3",
         " 4",
         "VENUS CUYEN",
         "CALVENTE GUSTAVO E",
         "6"
        ],
        [
         "4",
         " 5",
         "ELLAS LAS NADIES",
         "JURI FABIAN R",
         "6"
        ],
        [
         "5",
         " 6",
         "ALMA RUNNER",
         "BAEZ TOMAS D  3",
         "7"
        ],
        [
         "6",
         " 7",
         "KILL MODEL",
         "SOSA MIGUEL A O",
         "7"
        ],
        [
         "7",
         " 8",
         "VIOLENTA STORM",
         "ARREGUY FRANCISCO A (H)",
         "6"
        ],
        [
         "8",
         " 9",
         "ALEGRIA JOHAN",
         "ASERITO MAXIMILIANO",
         "7"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chaquetilla</th>\n",
       "      <th>competidor</th>\n",
       "      <th>jockey</th>\n",
       "      <th>edad_caballo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SUPER JANE</td>\n",
       "      <td>ARMOHA LEOPOLDO M</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>LA TABLET DE PLATA</td>\n",
       "      <td>GONZALEZ LUCAS F  4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BREEZA MANI</td>\n",
       "      <td>ORTEGA PAVON EDUARDO</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>VENUS CUYEN</td>\n",
       "      <td>CALVENTE GUSTAVO E</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ELLAS LAS NADIES</td>\n",
       "      <td>JURI FABIAN R</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>ALMA RUNNER</td>\n",
       "      <td>BAEZ TOMAS D  3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>KILL MODEL</td>\n",
       "      <td>SOSA MIGUEL A O</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>VIOLENTA STORM</td>\n",
       "      <td>ARREGUY FRANCISCO A (H)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ALEGRIA JOHAN</td>\n",
       "      <td>ASERITO MAXIMILIANO</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chaquetilla          competidor                   jockey edad_caballo\n",
       "0           1          SUPER JANE        ARMOHA LEOPOLDO M            6\n",
       "1           2  LA TABLET DE PLATA      GONZALEZ LUCAS F  4            7\n",
       "2           3         BREEZA MANI     ORTEGA PAVON EDUARDO            6\n",
       "3           4         VENUS CUYEN       CALVENTE GUSTAVO E            6\n",
       "4           5    ELLAS LAS NADIES            JURI FABIAN R            6\n",
       "5           6         ALMA RUNNER          BAEZ TOMAS D  3            7\n",
       "6           7          KILL MODEL          SOSA MIGUEL A O            7\n",
       "7           8      VIOLENTA STORM  ARREGUY FRANCISCO A (H)            6\n",
       "8           9       ALEGRIA JOHAN      ASERITO MAXIMILIANO            7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turf Scrapping - Menú principal\n",
      "-------------------------------\n",
      "1) Descargar resultados\n",
      "2) Actualizar base de resultados\n",
      "3) Actualizar rankings de jockeys y cuidadores\n",
      "4) Escanear programa\n",
      "5) Exportar información a archivos Excel\n",
      "6) Salir\n",
      "\n",
      "Exportando base de resultados...\n",
      "Exportando ranking de jockeys...\n",
      "Exportando ranking de cuidadores...\n",
      "Proceso finalizado\n",
      "Turf Scrapping - Menú principal\n",
      "-------------------------------\n",
      "1) Descargar resultados\n",
      "2) Actualizar base de resultados\n",
      "3) Actualizar rankings de jockeys y cuidadores\n",
      "4) Escanear programa\n",
      "5) Exportar información a archivos Excel\n",
      "6) Salir\n",
      "\n",
      "Saliendo...\n"
     ]
    }
   ],
   "source": [
    "menu()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
